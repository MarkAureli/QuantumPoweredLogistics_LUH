{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<p style=\"text-align: right\">\n",
    "Lennart Binkowski<br>\n",
    "Andreea-Iulia Lefterovici<br>\n",
    "Tobias J. Osborne<br>\n",
    "René Schwonnek<br>\n",
    "Sören Wilkening<br>\n",
    "Timo Ziegler<br>\n",
    "</p>\n",
    "\n",
    "<div style=\"text-align: justify; font-size: x-large\">\n",
    "    <b>Quantum-powered logistics: Towards an Efficient and Sustainable Supply Chain</b>\n",
    "</div>\n",
    "\n",
    "<div style='text-align: justify; font-size: large'>\n",
    "A quantum-ready Qiskit implementation of Quantum Tree Generator and Quantum Conic Programming\n",
    "</div>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a3f9154225ae5e7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this Jupyter notebook, we present a comprehensive Logistics Optimization Problem (LOP) class, an implementation of the Classical Tree Generator (CTG), as well as Qiskit-implementations of the Quantum Tree Generator (QTG) and the Quantum Conic Programming (QCP) as detailed in the main document.\n",
    "\n",
    "A Python version of at least 3.9 is required to execute the content of this notebook."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "774342e963648833"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import sys\n",
    "required_version = (3, 9)\n",
    "if sys.version_info < required_version:\n",
    "    raise ValueError(f\"This notebook requires Python {required_version[0]}.{required_version[1]} or later.\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:09:54.601279Z",
     "start_time": "2024-04-29T21:09:54.597169Z"
    }
   },
   "id": "8320c557c08e3c83",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Our notebook uses mostly standard python packages. However, as the task of implementing several classical-quantum algorithms for a complex problem class is anything but standard, we need to import several nonstandard libraries:\n",
    "- `gurobipy` for obtaining a good initial state for the QTG\n",
    "- `matplotlib` for graphical representation of circuits and results\n",
    "- `networkx` for a graphical representation of the PBS\n",
    "- `numpy` for all sorts of vector manipulation\n",
    "- `picos` for solving the arising semi-definite programs\n",
    "- `qiskit` for writing the quantum routines\n",
    "- `qiskit_aer` for a noiseless simulator\n",
    "- `qiskit_ibm_runtime` for a fake quantum backend, including noise simulation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cdb693f0bd325b50"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# standard libraries\n",
    "from collections import Counter\n",
    "from copy import deepcopy\n",
    "from csv import reader, writer\n",
    "from itertools import product\n",
    "from math import acos, sqrt\n",
    "from operator import countOf\n",
    "from queue import Queue\n",
    "from random import choice, choices, seed, randint, randrange, uniform\n",
    "from typing import Union\n",
    "\n",
    "# non-standard libraries\n",
    "import gurobipy as gp\n",
    "from matplotlib.pyplot import show\n",
    "from networkx import draw, Graph\n",
    "import numpy as np\n",
    "import picos\n",
    "from qiskit import transpile, QuantumCircuit, QuantumRegister, ClassicalRegister\n",
    "from qiskit.circuit import Instruction, CircuitInstruction\n",
    "from qiskit.circuit.library import IGate, SGate, RYGate, XGate, StatePreparation\n",
    "from qiskit_aer import AerSimulator\n",
    "from qiskit_ibm_runtime.fake_provider import FakeSherbrooke\n",
    "from scipy.linalg import eigh"
   ],
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:10:05.012677Z",
     "start_time": "2024-04-29T21:10:03.655664Z"
    }
   },
   "id": "initial_id",
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class LOP:\n",
    "    \"\"\"\n",
    "    A class used to represent a LOP.\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes\n",
    "    ----------\n",
    "    num_parts: int\n",
    "        Number of parts in the PBS\n",
    "    num_sites: int\n",
    "        Number of sites\n",
    "    coefficients: np.ndarray\n",
    "        Array of transportation cost matrices for each product\n",
    "    phi: dict[int, int]\n",
    "        Dictionary of constituents and their resultants from the PBS\n",
    "    reduced_phi: dict[int, int]\n",
    "        Dictionary of constituents and their resultants leaving out tuples involving assigned parts\n",
    "    parts: dict[int, int]\n",
    "        Dictionary of parts assigned to their layer in the PBS\n",
    "    layers: int\n",
    "        Number of layers in the PBS\n",
    "    psi: set[tuple[int, int]]\n",
    "        Pairs of parts constituting to the same resultants\n",
    "    reduced_psi: set[tuple[int, int]]\n",
    "        Pairs of parts constituting to the same resultants without assigned parts\n",
    "    free_parts: set[int]\n",
    "        Parts not assigned yet\n",
    "    available_sites: dict[int, set[int]]\n",
    "        Dictionary assigning each product a set of available sites\n",
    "    max_part: int\n",
    "        Maximal index of an unassigned part\n",
    "    num_var: int\n",
    "        Number of variables used to represent the PBS\n",
    "    assigned_costs: float\n",
    "        Costs arising from pre-assignment\n",
    "\n",
    "    Methods\n",
    "    -------\n",
    "    generate_coefficients(num_products: int, num_sites: int, save_to_file: bool = False) -> np.ndarray\n",
    "        Returns a 3D array of randomly drawn coefficients corresponding to the transportation costs of each part from\n",
    "        one site to another.\n",
    "    generate_pbs(num_layers: int, num_parts: int, save_to_file: bool = False) -> dict[int, int]\n",
    "        Returns a random PBS based on a given number of layers and a number of parts; returns a set of tuples\n",
    "        resembling all resultant/constituent connections.\n",
    "    from_parameters(num_parts: int, num_sites: int, num_layers: int, save_to_file: bool = False) -> LOP:\n",
    "        Returns an LOP by randomly generating transportation cost matrices as well as the PBS.\n",
    "    draw_pbs()\n",
    "        Draws the PBS using the networkx drawing library.\n",
    "    assign_parts(pre_assignments: dict[int, int])\n",
    "        Assigns parts to sites and updates the PBS structure as well as the variables according to the constraints.\n",
    "    assign_parts_inplace(pre_assignments: dict[int, int])\n",
    "        Assigns parts to sites that were not assigned a pre-assignment.\n",
    "    recall_parts_inplace(parts: set[int])\n",
    "        Recall parts after they have been preassigned.\n",
    "    var_index(part: int, site: int) -> int\n",
    "        Returns the index of the variable corresponding to the given part and the given site.\n",
    "    ctg(shots: int, initial_assignment: Union[int, str, dict[int, int]] = None, bias: float = 0.5) -> tuple[dict[int, int], float]\n",
    "        Returns the best assignment and its costs found after applying the CTG several times.\n",
    "    qtg() -> tuple[QuantumCircuit, int]\n",
    "        Returns the quantum circuit of the initial state based on classical optimization and the number of ancilla\n",
    "        qubits used in it.\n",
    "    assignment_from_bitstring(bitstring: Union[int, str]) -> dict[int, int]\n",
    "        Returns a dictionary of parts and assigned site based on a bitstring.\n",
    "    is_feasible(bitstring: Union[int, str, dict[int, int]) -> bool\n",
    "        Returns a boolean indicating whether the given assignment is a feasible solution.\n",
    "    get_objective_value(assignment: Union[int, str, dict[int, int]]) -> float:\n",
    "        Returns the objective value on a given assignment completed by any pre-assignment.\n",
    "    get_objective_value_inplace() -> float\n",
    "        Returns the objective value based on the pre-assignment. All unassigned parts are assigned the first site in\n",
    "        their available sites.\n",
    "    get_optimal_value() -> float:\n",
    "        Returns the optimal value amongst all possible assignments.\n",
    "    \"\"\"\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_coefficients(num_parts: int, num_sites: int, save_to_file: bool = False) -> np.ndarray:\n",
    "        \"\"\"\n",
    "        Returns a 3D array of randomly drawn coefficients corresponding to the transportation costs of each part from\n",
    "        one site to another.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        num_parts: int\n",
    "            Number of parts in the PBS\n",
    "        num_sites: int\n",
    "            Number of sites\n",
    "        save_to_file: bool\n",
    "            Whether to save the coefficient array to a .csv file\n",
    "        \"\"\"\n",
    "        # Initialize a numpy array of num_products-1 2D numpy arrays, each corresponding to the transportation costs of\n",
    "        # one part (the final product need not be shipped), to all zeros\n",
    "        data: np.ndarray = np.zeros(shape=(num_parts - 1, num_sites, num_sites), dtype=np.float64)\n",
    "        f1: np.ndarray = np.zeros(shape=num_parts, dtype=np.float64)\n",
    "        f2: np.ndarray = np.zeros(shape=(num_sites, num_sites), dtype=np.float64)\n",
    "        seed(a=1)\n",
    "\n",
    "        # Generate a random coefficient for each part's individual transportation expense between 0.05 and 1\n",
    "        for p in range(num_parts - 1):\n",
    "            f1[p] = randrange(50, 1000) / 1000\n",
    "\n",
    "        # Generate a random matrix with values between 0.1 and 1, displaying the transportation expense from one site to\n",
    "        # another\n",
    "        for s1 in range(num_sites - 1):\n",
    "            for s2 in range(s1 + 1, num_sites):\n",
    "                f2[s1, s2] = randrange(100, 1000) / 100\n",
    "\n",
    "        # Fill entries of the p-th transportation cost matrix with the product of the p-th individual product expense\n",
    "        # and the randomly generated transportation cost matrix rounded to two decimal places\n",
    "        for p in range(num_parts - 1):\n",
    "            for s1 in range(num_sites - 1):\n",
    "                for s2 in range(s1 + 1, num_sites):\n",
    "                    data[p, s1, s2] = round(f1[p] * f2[s1][s2], 2)\n",
    "\n",
    "        # If save_to_file is True the transportation cost matrix is saved to a .csv file as a table ordered by the\n",
    "        # part's index\n",
    "        if save_to_file:\n",
    "            header: list[str] = ['Part', 'Departure/Arrival site', 'Arrival/Departure site', 'Cost']\n",
    "\n",
    "            with open('cost_' + str(num_parts).zfill(2) + '_' + str(num_sites).zfill(2) + '.csv', 'w') as f:\n",
    "                file_writer: writer = writer(f)\n",
    "                file_writer.writerow(header)\n",
    "                for p in range(num_parts - 1):\n",
    "                    for s1 in range(num_sites - 1):\n",
    "                        for s2 in range(s1 + 1, num_sites):\n",
    "                            file_writer.writerow([p + 2, s1 + 1, s2 + 1, data[p, s1, s2]])\n",
    "\n",
    "            f.close()\n",
    "\n",
    "        return data\n",
    "\n",
    "    @staticmethod\n",
    "    def generate_pbs(num_layers: int, num_parts: int, save_to_file: bool = False) -> dict[int, int]:\n",
    "        \"\"\"\n",
    "        Returns a random PBS based on a given number of layers and a number of parts; returns a set of tuples\n",
    "        resembling all resultant/constituent connections.\n",
    "\n",
    "        num_layers: int\n",
    "            The number of layers in the PBS\n",
    "        num_parts: int\n",
    "            The number of parts in the PBS\n",
    "        save_to_file: bool\n",
    "            Whether to save the PBS to a .csv file\n",
    "        \"\"\"\n",
    "        while True:\n",
    "            # Create a list of layers with the final product assigned to the first layer\n",
    "            layers: list[list[int]] = [[] for _ in range(num_layers)]\n",
    "            layers[0].append(1)\n",
    "\n",
    "            # The remaining parts are distributed to layers of random sizes\n",
    "            current_level: int = 1\n",
    "            remaining_parts: list[int] = list(range(2, num_parts + 1))\n",
    "\n",
    "            while remaining_parts:\n",
    "                # If the current layer is the second only one part is assigned, otherwise some random amount between one\n",
    "                # and the number of remaining parts or the number of layers, depending on which is smaller\n",
    "                if current_level == 1:\n",
    "                    num_assigned: int = 1\n",
    "                else:\n",
    "                    num_assigned: int = randint(1, min(len(remaining_parts), num_layers))\n",
    "\n",
    "                # Add parts up to and excluding the num_assigned entry of remaining parts to the current layer and\n",
    "                # remove them from the remaining parts\n",
    "                layers[current_level].extend(remaining_parts[:num_assigned])\n",
    "                remaining_parts = remaining_parts[num_assigned:]\n",
    "\n",
    "                # Randomly choose a layer other than the top layer to assign parts to in the next iteration\n",
    "                current_level = randint(1, num_layers - 1)\n",
    "\n",
    "            # Check if each layer has at least one product\n",
    "            if all(layer for layer in layers):\n",
    "                break\n",
    "\n",
    "        # Relabel elements across layers sequentially\n",
    "        sequential_labels = 1\n",
    "        for layer in range(num_layers):\n",
    "            layer_size = len(layers[layer])\n",
    "            layers[layer] = list(range(sequential_labels, sequential_labels + layer_size))\n",
    "            sequential_labels += layer_size\n",
    "\n",
    "        phi: dict[int, int] = {}\n",
    "\n",
    "        # Iterate through all pairs of consecutive layers\n",
    "        for layer in range(1, len(layers)):\n",
    "            resultant_layer: list[int] = layers[layer - 1]\n",
    "            constituent_layer: list[int] = layers[layer]\n",
    "\n",
    "            # Initialize the recent resultant to the minimum of resultant_layer\n",
    "            recent_resultant: int = min(resultant_layer)\n",
    "\n",
    "            # Iterate through each constituent in the constituent layer\n",
    "            for constituent in constituent_layer:\n",
    "                # Randomly select an element from the current layer (greater than or equal to recent_element)\n",
    "                eligible_resultants: list[int] = [p for p in resultant_layer if p >= recent_resultant]\n",
    "\n",
    "                # Check if there are eligible elements in the current layer and update the most recently selected\n",
    "                # element\n",
    "                if eligible_resultants:\n",
    "                    current_element: int = choice(eligible_resultants)\n",
    "                    recent_resultant = current_element\n",
    "                else:\n",
    "                    current_element = choice(resultant_layer)\n",
    "\n",
    "                # Add the pair to the list (or set phi in our case )\n",
    "                phi[constituent] = current_element\n",
    "\n",
    "        # If save_to_file is True the PBS is saved to a .csv file as a table of constituent and resultant\n",
    "        if save_to_file:\n",
    "            header = ['Lower level constituent part', 'Higher level resultant part']\n",
    "\n",
    "            with open('pbs_' + str(num_parts).zfill(2) + '.csv', 'w') as f:\n",
    "                file_writer = writer(f)\n",
    "                file_writer.writerow(header)\n",
    "                for constituent, resultant in phi.items():\n",
    "                    file_writer.writerow([constituent, resultant])\n",
    "\n",
    "            f.close()\n",
    "        # Return the pairs (the set phi)\n",
    "        return phi\n",
    "\n",
    "    def __init__(self, coefficients: Union[str, np.ndarray], pbs: Union[str, dict[int, int]]):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        coefficients: Union[str, np.ndarray]\n",
    "            A .csv file's name as a string or an array containing the transportation cost matrices for each product\n",
    "        pbs: Union[str, dict[int, int]]\n",
    "            A .csv file's name as a string or a dictionary containing all resultant/constituent connections of the PBS\n",
    "        \"\"\"\n",
    "        # If input coefficients is a string read the transportation cost matrices from the corresponding .csv file\n",
    "        if isinstance(coefficients, str):\n",
    "            with open(coefficients, newline='') as coefficients_file:\n",
    "                coefficients_content = list(reader(coefficients_file, delimiter=',', quotechar='|'))\n",
    "\n",
    "            m_str, _, n_str, _ = next(row for row in reversed(coefficients_content) if len(row) != 0)\n",
    "            self.num_parts: int = int(m_str)\n",
    "            self.num_sites: int = int(n_str)\n",
    "\n",
    "            # Construct an array of triangular matrices\n",
    "            self.coefficients: np.ndarray = np.zeros((self.num_parts - 1, self.num_sites, self.num_sites), dtype=np.float64)\n",
    "\n",
    "            for row in coefficients_content[1::]:\n",
    "                if len(row) != 0:\n",
    "                    self.coefficients[int(row[0]) - 2, int(row[1]) - 1, int(row[2]) - 1] = float(row[3])\n",
    "\n",
    "        # Otherwise, initialize coefficients to the numpy array\n",
    "        elif isinstance(coefficients, np.ndarray):\n",
    "            self.num_parts: int = coefficients.shape[0] + 1\n",
    "            self.num_sites: int = coefficients.shape[1]\n",
    "            self.coefficients: np.ndarray = coefficients\n",
    "\n",
    "        else:\n",
    "            raise TypeError('Coefficients must be a filepath (String) or a numpy array')\n",
    "\n",
    "        # Fill the transportation matrices' lower triangles by adding the transposed\n",
    "        self.coefficients += self.coefficients.transpose(0, 2, 1)\n",
    "\n",
    "        # If pbs is a str read phi corresponding to resultant/constituent connections from the corresponding .csv file\n",
    "        if isinstance(pbs, str):\n",
    "            self.phi: dict[int, int] = {}\n",
    "            with open(pbs, newline='') as pbs_file:\n",
    "                pbs_content: reader = reader(pbs_file, delimiter=',', quotechar='|')\n",
    "                next(pbs_file)\n",
    "                for row in pbs_content:\n",
    "                    if len(row) != 0:\n",
    "                        self.phi[int(row[0])] = int(row[1])\n",
    "\n",
    "        # Otherwise, initialize phi to a deep copy of the input set\n",
    "        elif isinstance(pbs, dict):\n",
    "            self.phi: dict[int, int] = deepcopy(pbs)\n",
    "\n",
    "        else:\n",
    "            raise TypeError('PBS must be a filepath (String) or a dictionary of int keys and int values')\n",
    "\n",
    "        # Initialize a set that contains remaining constituent/resultant connections after parts were pre-assigned\n",
    "        self.reduced_phi: dict[int, int] = deepcopy(self.phi)\n",
    "\n",
    "        # Create a dictionary assigning each product to its layer in the PBS\n",
    "        self.parts: dict[int, int] = {}\n",
    "\n",
    "        # Identify the products that are highest in the product chain\n",
    "        resultants: set[int] = {q for q in self.phi.values() if q not in {p for p in self.phi.keys()}}\n",
    "        layer: int = 1\n",
    "\n",
    "        # Starting at the first layer assign each resultant to the current layer\n",
    "        while resultants:\n",
    "            constituents: set[int] = set()\n",
    "            for q in resultants:\n",
    "                self.parts[q] = layer\n",
    "                # Update the resultants to be all parts sharing a tuple with one of the recent resultants\n",
    "                constituents |= {p for (p, r) in self.phi.items() if r == q}\n",
    "            resultants = constituents\n",
    "            # Increase the layer index by one\n",
    "            layer += 1\n",
    "        self.layers: int = layer - 1\n",
    "\n",
    "        # Construct the set psi of tuple of parts constituting to the same resultants\n",
    "        self.psi: set[tuple[int, int]] = set()\n",
    "        for r in self.parts.keys():\n",
    "            count: int = 0\n",
    "            buffer: set[int] = set()\n",
    "            # Add all constituents of the current resultant to buffer\n",
    "            for p, q in self.phi.items():\n",
    "                if q == r:\n",
    "                    count += 1\n",
    "                    buffer.add(p)\n",
    "            # If there are more than two constituents in buffer add each valid tuple to psi\n",
    "            if count >= 2:\n",
    "                [self.psi.add((p1, p2)) for p1 in buffer for p2 in buffer if p1 < p2]\n",
    "\n",
    "        # Initialize a set that contains the remaining tuple of parts constituting to the same resultant after\n",
    "        # pre-assignment\n",
    "        self.reduced_psi: set[tuple[int, int]] = deepcopy(self.psi)\n",
    "\n",
    "        # Initialize the set of parts not assigned yet\n",
    "        self.free_parts: set[int] = {p for p in self.parts.keys()}\n",
    "\n",
    "        # Initialize a dictionary assigning all sites to each part\n",
    "        self.available_sites: dict[int, Union[int, set[int]]] = {p: set(range(self.num_sites)) for p in self.parts.keys()}\n",
    "\n",
    "        # Initialize the maximal index of parts not assigned yet\n",
    "        self.max_part: int = max(self.free_parts)\n",
    "\n",
    "        # Initialize the total number of variables to the sum of available sites of each product\n",
    "        self.num_var: int = self.var_index(self.max_part, max(self.available_sites[self.max_part])) + 1\n",
    "\n",
    "        # Initialize the costs arising from pre-assignment\n",
    "        self.assigned_costs: float = 0\n",
    "\n",
    "    @classmethod\n",
    "    def from_parameters(cls, num_parts: int, num_sites: int, num_layers: int, save_to_file: bool = False) -> 'LOP':\n",
    "        \"\"\"\n",
    "        Returns an LOP by randomly generating transportation cost matrices as well as the PBS.\n",
    "\n",
    "        num_parts: int\n",
    "            Number of parts\n",
    "        num_sites: int\n",
    "            Number of sites\n",
    "        num_layers: int\n",
    "            Number of layers in the PBS\n",
    "        save_to_file: bool\n",
    "            Whether to save the LOP's underlying structures to .csv files\n",
    "        \"\"\"\n",
    "        return cls(coefficients=LOP.generate_coefficients(num_parts, num_sites, save_to_file),\n",
    "                   pbs=LOP.generate_pbs(num_layers, num_parts, save_to_file))\n",
    "\n",
    "    def draw_pbs(self):\n",
    "        \"\"\"\n",
    "        Draws the PBS using the networkx drawing library.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize an empty networkx graph\n",
    "        pbs_graph: Graph = Graph()\n",
    "        # Capture the number of items in each layer of the PBS in a list counting the layer appearance in the parts dict\n",
    "        layer_sizes: list[int] = [0 for _ in range(self.layers)]\n",
    "        for layer in range(self.layers):\n",
    "            layer_sizes[layer] = countOf(self.parts.values(), (layer + 1))\n",
    "\n",
    "        # Add a node to the graph for each part indexing it according to the number of nodes in previous layers and its\n",
    "        # position in the current layer starting at node index one\n",
    "        for i in range(self.layers):\n",
    "            for j in range(layer_sizes[i]):\n",
    "                node_index: int = sum(layer_sizes[:i]) + j + 1\n",
    "                pbs_graph.add_node(node_index, layer=i + 1)\n",
    "\n",
    "        # Add edges to the graph based on pairs of constituent and resultant provided by phi\n",
    "        for (p, q) in self.phi.items():\n",
    "            pbs_graph.add_edge(p, q)\n",
    "\n",
    "        # Draw the graph by positioning each node according to its position of the layer (y) and within the layer (x)\n",
    "        pos: dict[int, tuple[int, int]] = {}\n",
    "        max_layer_size: int = max(layer_sizes)\n",
    "        for i in range(self.layers):\n",
    "            for j in range(layer_sizes[i]):\n",
    "                node_index: int = sum(layer_sizes[:i]) + j + 1\n",
    "                if i == 0 and j == 0:  # For the first node in the first layer\n",
    "                    x: int = (max_layer_size - 1) // 2\n",
    "                else:\n",
    "                    x: int = j * (max_layer_size - 1) // (layer_sizes[i] - 1)\n",
    "                y: int = -i\n",
    "                pos[node_index] = (x, y)\n",
    "        draw(G=pbs_graph, pos=pos, with_labels=True, node_size=500, node_color='skyblue', font_size=10, font_weight='bold', edgecolors='black')\n",
    "        show()\n",
    "\n",
    "    def assign_parts(self, pre_assignments: dict[int, int]):\n",
    "        \"\"\"\n",
    "        Assigns parts to sites and updates the PBS structure as well as the variables according to the constraints.\n",
    "\n",
    "        pre_assignments: dict[int, int]\n",
    "            Dictionary of parts with site to be assigned to\n",
    "        \"\"\"\n",
    "\n",
    "        assigned_parts: set[int] = set(pre_assignments.keys())\n",
    "\n",
    "        # Update free_parts to exclude the assigned parts\n",
    "        self.free_parts = self.parts.keys() - assigned_parts\n",
    "\n",
    "        # Update available_sites such that each assigned product's value narrows down to its assigned site\n",
    "        self.available_sites = {p: set(range(self.num_sites)) for p in self.free_parts}\n",
    "        for (p, s) in pre_assignments.items():\n",
    "            self.available_sites[p] = s\n",
    "\n",
    "        # For each assigned part discard its assigned site from all available_sites for parts which are constituents/\n",
    "        # resultants of the assigned part or share a common resultant\n",
    "        for (p1, s) in pre_assignments.items():\n",
    "            affected_constituents: set[int] = {p for p, q in self.phi.items() if p1 == q}\n",
    "            affected_resultants: set[int] = {q for p, q in self.phi.items() if p1 == p}\n",
    "            same_part_group: set[int] = {p for pair in self.psi for p in pair if p1 in pair}\n",
    "            for p2 in self.free_parts & (affected_constituents | affected_resultants | same_part_group):\n",
    "                self.available_sites[p2].discard(s)\n",
    "                \n",
    "        # reiterate over parts and check for forced assignments or infeasibility\n",
    "        for p in self.free_parts:\n",
    "            if len(self.available_sites[p]) == 0:\n",
    "                raise ValueError(\"Pre-assignment made LOP infeasible\")\n",
    "            elif len(self.available_sites[p]) == 1:\n",
    "                self.available_sites[p] = next(iter(self.available_sites[p]))\n",
    "                self.free_parts.remove(p)   \n",
    "                \n",
    "        # Update reduced_phi to only contain tuples with both parts being unassigned\n",
    "        self.reduced_phi = {p: q for (p, q) in self.phi.items() if p in self.free_parts and q in self.free_parts}\n",
    "\n",
    "        # Update reduced_psi to only contain tuples with both parts being unassigned\n",
    "        self.reduced_psi = {pair for pair in self.psi if\n",
    "                            pair[0] in self.free_parts and pair[1] in self.free_parts}\n",
    "        \n",
    "        # Update the maximal index of unassigned parts\n",
    "        self.max_part = max(self.free_parts) if self.free_parts else 0\n",
    "\n",
    "        # Update the number of variables removing any variable of an assigned product\n",
    "        self.num_var = self.var_index(self.max_part, max(self.available_sites[self.max_part])) + 1 \\\n",
    "            if self.max_part != 0 else 0\n",
    "\n",
    "        # Update the assigned costs by adding costs for transport between any constituent- and resultant site where both\n",
    "        # are readily assigned\n",
    "        self.assigned_costs = 0\n",
    "        for p1, p2 in {(p, q) for (p, q) in self.phi.items() if p in assigned_parts and q in assigned_parts}:\n",
    "            self.assigned_costs += self.coefficients[p1 - 2][self.available_sites[p1]][self.available_sites[p2]]\n",
    "\n",
    "    def assign_parts_inplace(self, pre_assignments: dict[int, int]):\n",
    "        \"\"\"\n",
    "        Assigns parts to sites that were not assigned a pre-assignment.\n",
    "\n",
    "        pre_assignments: dict[int, int]\n",
    "            Dictionary of parts with site to be assigned to\n",
    "        \"\"\"\n",
    "\n",
    "        if pre_assignments.keys() & (self.parts.keys() - self.free_parts):\n",
    "            raise ValueError(\"Tried to reassign parts that were previously assigned\")\n",
    "        \n",
    "        full_assignment: dict[int, int] = {p: self.available_sites[p] for p in (self.parts.keys() - self.free_parts)} | pre_assignments\n",
    "        self.assign_parts(pre_assignments=full_assignment)\n",
    "\n",
    "    def recall_parts_inplace(self, parts: set[int]):\n",
    "        \"\"\"\n",
    "        Recall parts after they have been preassigned.\n",
    "\n",
    "        parts: set[int]\n",
    "            Parts to be unassigned again after pre-assignment\n",
    "        \"\"\"\n",
    "        if parts & self.free_parts:\n",
    "            raise ValueError(\"Tried to recall parts that were not assigned in the first place\")\n",
    "        full_assignment: dict[int, int] = {p: self.available_sites[p] for p in (self.parts.keys() - self.free_parts) - parts}\n",
    "        self.assign_parts(pre_assignments=full_assignment)\n",
    "\n",
    "    def var_index(self, part: int, site: int) -> int:\n",
    "        \"\"\"\n",
    "        Returns the index of the variable corresponding to the given part and the given site.\n",
    "\n",
    "        part: int\n",
    "            Part the variable corresponds to\n",
    "        site: int\n",
    "            Site for the given part the variable corresponds to\n",
    "        \"\"\"\n",
    "\n",
    "        # Sum up the available sites for all free parts preceding the given part and the available sites for the given\n",
    "        # part preceding the given site\n",
    "        return sum(len(self.available_sites[p]) for p in self.free_parts if p < part) + sum(\n",
    "            s < site for s in self.available_sites[part])\n",
    "    \n",
    "    def ctg(self, shots: int, initial_assignment: Union[int, str, dict[int, int]] = None, bias: float = 0.5) -> tuple[dict[int, int], float]:\n",
    "        \"\"\"\n",
    "        Returns the best assignment and its costs found after applying the CTG several times.\n",
    "        \n",
    "        shots: int\n",
    "            Number of CTG applications\n",
    "        initial_assignment: str\n",
    "            Initial candidate for a good solution which may be biased towards\n",
    "        bias: float\n",
    "            Bias towards the candidate solution\n",
    "        \"\"\"\n",
    "        if initial_assignment is None:\n",
    "            initial_assignment = {}\n",
    "            bias = 0.5\n",
    "        minimizer: dict[int, int] = {}\n",
    "        minimum: float = np.inf\n",
    "        seed(a=1)\n",
    "        for shot in range(shots):\n",
    "            control_bits: list[bool] = [False] * len(self.free_parts)\n",
    "            infeasible: bool = False\n",
    "            current_assignment: dict[int, int] = {}\n",
    "            for p, p_index in zip(sorted(self.free_parts), range(len(self.free_parts))):\n",
    "                sorted_sites: list[int] = sorted(self.available_sites[p])\n",
    "                clashing_parts: list[int] = [q for q in self.free_parts if q < p\n",
    "                                             and ((p, q) in self.reduced_phi.items()\n",
    "                                              or (q, p) in self.reduced_phi.items()\n",
    "                                              or (p, q) in self.reduced_psi\n",
    "                                              or (q, p) in self.reduced_psi)]\n",
    "                if (not any((q, sorted_sites[0]) in current_assignment.items() for q in clashing_parts)\n",
    "                        and uniform(0, 1) < (bias if (p, sorted_sites[0]) in initial_assignment.items() else 1 - bias)):\n",
    "                        current_assignment[p] = sorted_sites[0]\n",
    "                        control_bits[p_index] = True\n",
    "                        continue\n",
    "                for s in sorted_sites[1:-1]:\n",
    "                    if (not (any((q, s) in current_assignment.items() for q in clashing_parts))\n",
    "                            and uniform(0, 1) < (bias if (p, s) in initial_assignment.items() else 1 - bias)):\n",
    "                            current_assignment[p] = s\n",
    "                            control_bits[p_index] = True\n",
    "                            continue\n",
    "                if not (any((q, sorted_sites[-1]) in current_assignment.items() for q in clashing_parts)):\n",
    "                    current_assignment[p] = sorted_sites[-1]\n",
    "                    control_bits[p_index] = True\n",
    "                \n",
    "                if not control_bits[p_index]:\n",
    "                    infeasible = True\n",
    "                    break\n",
    "            if infeasible:\n",
    "                continue\n",
    "            if self.get_objective_value(assignment=current_assignment) < minimum:\n",
    "                minimizer = current_assignment\n",
    "                minimum = self.get_objective_value(assignment=current_assignment)\n",
    "        if minimum == np.inf:\n",
    "            raise RuntimeError('Could not find any feasible solution with CTG')\n",
    "        return minimizer, minimum\n",
    "    \n",
    "    def create_model(self) -> gp.Model:\n",
    "        model = gp.Model('Logistics')\n",
    "        model.setParam('OutputFlag', 0)\n",
    "\n",
    "        # For all available sites of each free product add a binary variable to the gurobipy model and collect all in a\n",
    "        # dict identified by the tuples (part, site)\n",
    "        variables = {}\n",
    "        for p in self.free_parts:\n",
    "            for s in self.available_sites[p]:\n",
    "                variables[p, s] = model.addVar(name=f\"x[{p},{s}]\", vtype=gp.GRB.BINARY)\n",
    "\n",
    "        # Set up the objective function in the gurobipy model by summing over all terms where neither the resultant nor\n",
    "        # the constituent is assigned together with the terms where either the resultant or the constituent is assigned\n",
    "        model.setObjective(\n",
    "            self.assigned_costs +\n",
    "            gp.quicksum(self.coefficients[p1 - 2, s1, s2] * variables[(p1, s1)] * variables[(p2, s2)]\n",
    "                        for (p1, p2) in self.reduced_phi.items()\n",
    "                        for s1 in self.available_sites[p1]\n",
    "                        for s2 in self.available_sites[p2]) +\n",
    "            gp.quicksum(self.coefficients[p1 - 2, s, self.available_sites[p2]] * variables[(p1, s)]\n",
    "                        for p1 in self.free_parts\n",
    "                        for p2 in (self.parts.keys() - self.free_parts)\n",
    "                        if (p1, p2) in self.phi.items()\n",
    "                        for s in self.available_sites[p1]) +\n",
    "            gp.quicksum(self.coefficients[p1 - 2, s, self.available_sites[p1]] * variables[(p2, s)]\n",
    "                        for p1 in (self.parts.keys() - self.free_parts)\n",
    "                        for p2 in self.free_parts\n",
    "                        if (p1, p2) in self.phi.items()\n",
    "                        for s in self.available_sites[p2]), sense=gp.GRB.MINIMIZE)\n",
    "\n",
    "        # For each part add the one hot constraint to the gurobipy model\n",
    "        for p in self.free_parts:\n",
    "            model.addConstr(gp.quicksum(variables[(p, s)] for s in self.available_sites[p]) == 1,\n",
    "                            name=f\"{p} is produced exactly once\")\n",
    "\n",
    "        # Add the phi constraint to the gurobipy model\n",
    "        model.addConstr(gp.quicksum(variables[(p1, s)] * variables[(p2, s)] for (p1, p2) in self.reduced_phi.items()\n",
    "                                    for s in (self.available_sites[p1] & self.available_sites[p2])) == 0,\n",
    "                        name=f\"phi constraint\")\n",
    "        \n",
    "        # Add the psi constraint to the gurobipy model\n",
    "        model.addConstr(gp.quicksum(variables[(p1, s)] * variables[(p2, s)] for p1, p2 in self.reduced_psi\n",
    "                                    for s in (self.available_sites[p1] & self.available_sites[p2])) == 0,\n",
    "                        name=f\"psi constraint\")\n",
    "\n",
    "        return model\n",
    "\n",
    "    def qtg(self) -> tuple[QuantumCircuit, int]:\n",
    "        \"\"\"\n",
    "        Returns the quantum circuit of the initial state based on classical optimization and the number of ancilla\n",
    "        qubits used in it.\n",
    "        \"\"\"\n",
    "        model = self.create_model()\n",
    "        model.setParam('FeasibilityTol', 1e-9)\n",
    "        model.setParam('IntFeasTol', 1e-9)\n",
    "        model.setParam(\"IterationLimit\", 1)\n",
    "\n",
    "        # Process pending modifications, write model to a .lp file and optimize it using only one simplex step\n",
    "        model.update()\n",
    "        model.optimize()\n",
    "\n",
    "        # Save the optimal solution found by gurobi to a bitstring\n",
    "        assignment: list[bool] = [bool(var.X) for var in model.getVars()]\n",
    "\n",
    "        anc: QuantumRegister = QuantumRegister(len(self.free_parts), 'ancilla')\n",
    "        main: QuantumRegister = QuantumRegister(self.num_var, 'main')\n",
    "        qc: QuantumCircuit = QuantumCircuit(anc, main)\n",
    "        parts = sorted(self.free_parts)\n",
    "        bias: float = self.num_var / 4.0\n",
    "        false_angle: float = 2 * acos(sqrt((1.0 + bias) / (2.0 + bias)))\n",
    "        true_angle: float = 2 * acos(sqrt(1.0 / (2.0 + bias)))\n",
    "\n",
    "        for p, p_index in zip(parts, range(len(parts))):\n",
    "\n",
    "            # For each free part collect its resultants as well as preceding parts with a common resultant\n",
    "            clash_parts: list[int] = [q for q in self.free_parts if q < p\n",
    "                                         and ((p, q) in self.reduced_phi.items()\n",
    "                                              or (q, p) in self.reduced_phi.items()\n",
    "                                              or (p, q) in self.reduced_psi\n",
    "                                              or (q, p) in self.reduced_psi)]\n",
    "\n",
    "            # Collect qubit indices corresponding to assign a clash product to the first available site of the current\n",
    "            # part\n",
    "            sites = sorted(self.available_sites[p])\n",
    "            clash_qubits: list[int] = [main[self.var_index(q, sites[0])] for q in clash_parts\n",
    "                                       if sites[0] in self.available_sites[q]]\n",
    "\n",
    "            # If clashes with the current part's first available site exist rotate all clashing qubits about the y-axis\n",
    "            # by an angle depending on the corresponding value of the model's solution controlled by the first\n",
    "            # #(qubit clashes) ancilla qubits\n",
    "            if clash_qubits:\n",
    "                qc.append(RYGate(theta=true_angle if assignment[self.var_index(p, sites[0])] else false_angle).\n",
    "                          control(num_ctrl_qubits=len(clash_qubits), ctrl_state=0),\n",
    "                          clash_qubits + [main[self.var_index(p, sites[0])]])\n",
    "\n",
    "            # Otherwise, perform a y-rotation on the qubit corresponding to the current part's first available site by\n",
    "            # the angle depending on the corresponding value of the model's solution\n",
    "            else:\n",
    "                qc.ry(theta=true_angle if assignment[self.var_index(p, sites[0])] else false_angle,\n",
    "                      qubit=main[self.var_index(p, sites[0])])\n",
    "\n",
    "            # Perform an X-gate on the qubit corresponding to the current part's first available site controlled by the\n",
    "            # ancilla corresponding to the current part\n",
    "            qc.cx(main[self.var_index(p, sites[0])], anc[p_index])\n",
    "\n",
    "            # For the remaining available sites of the current part, except for the last, collect all qubit indices\n",
    "            # corresponding to the same site for clashing parts and perform a y-rotation on the qubit corresponding to\n",
    "            # the current part and current site by the angle depending on the corresponding value of the model's\n",
    "            # solution if the first #(qubit clashes) + 1 are in the all zero state.\n",
    "            for s in sites[1:-1]:\n",
    "                clash_qubits: list[int] = [main[self.var_index(q, s)] for q in clash_parts\n",
    "                                           if s in self.available_sites[q]]\n",
    "                qc.append(RYGate(theta=true_angle if assignment[self.var_index(p, s)] else false_angle).\n",
    "                          control(num_ctrl_qubits=len(clash_qubits) + 1, ctrl_state=0),\n",
    "                          [anc[p_index]] + clash_qubits + [main[self.var_index(p, s)]])\n",
    "                qc.cx(main[self.var_index(p, s)], anc[p_index])\n",
    "\n",
    "            # For the last available site of the current part, collect all qubit indices corresponding to the same site\n",
    "            # for clashing parts and perform an X-gate on\n",
    "            clash_qubits: list[int] = [main[self.var_index(q, sites[-1])] for q in clash_parts\n",
    "                                       if sites[-1] in self.available_sites[q]]\n",
    "            qc.append(XGate().control(num_ctrl_qubits=len(clash_qubits) + 1, ctrl_state=0),\n",
    "                      [anc[0]] + clash_qubits + [main[self.var_index(p, sites[-1])]])\n",
    "            qc.cx(main[self.var_index(p, sites[-1])], anc[p_index])\n",
    "            qc.draw('mpl')\n",
    "        return qc, anc.size\n",
    "    \n",
    "    def search_unitaries(self) -> list[QuantumCircuit]:\n",
    "        \n",
    "        _identity: QuantumCircuit = QuantumCircuit(self.num_var)\n",
    "        _identity.id(range(0, self.num_var))\n",
    "        \n",
    "        _x_mixer: QuantumCircuit = QuantumCircuit(self.num_var)\n",
    "        _x_mixer.rx(0.1, range(self.num_var))\n",
    "        \n",
    "        _z_mixer: QuantumCircuit = QuantumCircuit(self.num_var)\n",
    "        _z_mixer.rz(0.15, range(self.num_var))\n",
    "        \n",
    "        return [_identity, _x_mixer, _z_mixer]\n",
    "\n",
    "    def assignment_from_bitstring(self, bitstring: Union[int, str]) -> dict[int, int]:\n",
    "        \"\"\"\n",
    "        Returns a dictionary of parts and assigned site based on a bitstring.\n",
    "\n",
    "        bitstring: Union[int, str]\n",
    "            A bitstring representing the assignment of parts to sites in right to left order\n",
    "        \"\"\"\n",
    "\n",
    "        # If bitstring is a decimal, convert it to binary representation, remove the prefix '0b', append trailing zeros\n",
    "        # such that length matches number of variables and reverse it\n",
    "        if isinstance(bitstring, int):\n",
    "            tmp: str = bin(bitstring)[2:].zfill(self.num_var)[::-1]\n",
    "\n",
    "        # Otherwise, reverse the bitstring\n",
    "        else:\n",
    "            tmp: str = bitstring[::-1]\n",
    "\n",
    "        # For each unassigned part identify the section in the bitstring and assign the site corresponding to a one in\n",
    "        # the bitstring to the part in a dict\n",
    "        result: dict[int, int] = {}\n",
    "        parts: list = sorted(self.free_parts)\n",
    "        for p in parts:\n",
    "            sites: list[int] = sorted(self.available_sites[p])\n",
    "            tmp2 = tmp[:len(sites)]\n",
    "            for b, position in zip(tmp2, sites):\n",
    "                if b == '1':\n",
    "                    result[p] = position\n",
    "                    break\n",
    "            tmp = tmp[len(sites):]\n",
    "        return result\n",
    "\n",
    "    def is_feasible(self, assignment: Union[int, str, dict[int, int]]) -> bool:\n",
    "        \"\"\"\n",
    "        Returns a boolean indicating whether the given assignment is a feasible solution.\n",
    "\n",
    "        assignment: Union[int, str, dict[int, int]]\n",
    "            An assignment of parts to sites\n",
    "        \"\"\"\n",
    "        if isinstance(assignment, int):\n",
    "            assignment = bin(assignment)[2:]\n",
    "            \n",
    "        if isinstance(assignment, str):\n",
    "            if assignment.count('1') != len(self.free_parts):\n",
    "                return False # each part must be \n",
    "            assignment = self.assignment_from_bitstring(assignment)\n",
    "        elif not isinstance(assignment, dict):\n",
    "            raise TypeError('Assignment must be either an integer, a string or a dictionary')\n",
    "        \n",
    "        # Check whether each part is assigned to exactly one site\n",
    "        if set(assignment.keys()) != self.free_parts:\n",
    "            return False\n",
    "\n",
    "        # Check whether the sites for pairs of constituent and resultant disagree\n",
    "        for p1, p2 in self.reduced_phi:\n",
    "            if assignment[p1] == assignment[p2]:\n",
    "                return False\n",
    "\n",
    "        # Check whether the sites for pairs of constituents sharing a common resultant disagree\n",
    "        for p1, p2 in self.reduced_psi:\n",
    "            if assignment[p1] == assignment[p2]:\n",
    "                return False\n",
    "\n",
    "        return True\n",
    "    \n",
    "    def get_assignment(self) -> dict[int, int]:\n",
    "        return {p: s for (p, s) in self.available_sites.items() if p not in self.free_parts}\n",
    "\n",
    "    def get_objective_value(self, assignment: Union[int, str, dict[int, int]]) -> float:\n",
    "        \"\"\"\n",
    "        Returns the objective value on a given assignment completed by any pre-assignment.\n",
    "\n",
    "        assignment: Union[int, str, dict[int, set[int]]]\n",
    "            Assignment in one of its various forms\n",
    "        \"\"\"\n",
    "\n",
    "        # If assignment is a bitstring or a decimal, convert it to a dictionary. Otherwise, leave it as it is\n",
    "        if isinstance(assignment, (int, str)):\n",
    "            assignment = self.assignment_from_bitstring(bitstring=assignment)\n",
    "        elif not isinstance(assignment, dict):\n",
    "            raise TypeError('Assignment must be either an integer, a string or a dictionary')\n",
    "\n",
    "        # Complete the assignment by adding the pre-assignments\n",
    "        for p in (self.parts.keys() - self.free_parts):\n",
    "            assignment[p] = self.available_sites[p]\n",
    "\n",
    "        # Add the transportation cost for each pair in the PBS to the result\n",
    "        result: float = 0\n",
    "        for (p1, p2) in self.phi.items():\n",
    "            result += self.coefficients[p1 - 2][assignment[p1]][assignment[p2]]\n",
    "        return result\n",
    "\n",
    "    def get_objective_value_inplace(self) -> float:\n",
    "        \"\"\"\n",
    "        Returns the objective value based on the pre-assignment.\n",
    "        \"\"\"\n",
    "        if self.free_parts:\n",
    "            raise RuntimeError('All parts have to be assigned in order to calculate the objective value')\n",
    "        result: float = 0\n",
    "        for p1, p2 in self.phi.items():\n",
    "            result += self.coefficients[p1 - 2][self.available_sites[p1]][self.available_sites[p2]]\n",
    "        return result\n",
    "\n",
    "    def get_optimal_value(self) -> float:\n",
    "        \"\"\"\n",
    "        Returns the optimal value amongst all possible assignments.\n",
    "        \"\"\"\n",
    "\n",
    "        # Initialize the output to infinity\n",
    "        result: float = np.inf\n",
    "\n",
    "        # Compare all assignments where unassigned parts are assigned to one available site\n",
    "        for assignment in (tuple(zip(self.free_parts, sites)) for sites in\n",
    "                           product(*(self.available_sites[p] for p in self.free_parts))):\n",
    "\n",
    "            # Create a deepcopy of the LOP and assign unassigned parts\n",
    "            instance_copy: LOP = deepcopy(self)\n",
    "            instance_copy.assign_parts_inplace(assignment)\n",
    "\n",
    "            # Feasibility check (one-hot constraints are automatically fulfilled by construction)\n",
    "            feasible: bool = True\n",
    "\n",
    "            # Check whether the sites for pairs of constituent and resultant disagree\n",
    "            for (p1, p2) in instance_copy.phi.items():\n",
    "                feasible &= (instance_copy.available_sites[p1] != instance_copy.available_sites[p2])\n",
    "\n",
    "            # Check whether the sites for pairs of constituents sharing a common resultant disagree\n",
    "            for (p1, p2) in instance_copy.psi:\n",
    "                feasible &= (instance_copy.available_sites[p1] != instance_copy.available_sites[p2])\n",
    "\n",
    "            # If the assigment is feasible and its objective value is lower than the previous lowest update result\n",
    "            if feasible:\n",
    "                result = min(result, instance_copy.get_objective_value_inplace())\n",
    "\n",
    "            del instance_copy\n",
    "        return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:10:06.766332Z",
     "start_time": "2024-04-29T21:10:06.718663Z"
    }
   },
   "id": "d59e0dafa90051cc",
   "execution_count": 3
  },
  {
   "cell_type": "markdown",
   "source": [
    "The next cell holds the `moment_matrices`-routine which constructs the objective and constraints for the auxiliary SDP. For a given LOP instance, consider the *feasible subspace*\n",
    "\\begin{equation}\n",
    "    \\mathcal{S} = \\text{span}(\\vert z\\rangle\\, :\\, z \\text{ is a feasible solution}),\n",
    "\\end{equation}\n",
    "the projection $P_{\\text{f}}$ on it, and the projection $P_{\\text{if}}$ on its orthogonal complement. Furthermore, let\n",
    "\\begin{equation}\n",
    "    C = \\sum_{z} c(z) \\vert z\\rangle\\langle z\\vert\n",
    "\\end{equation}\n",
    "be the instance's objective Hamiltonian, where $c(z)$ denotes the classical objective value of the bitstring $z$. For a given initial state $\\vert \\iota\\rangle$ and a family of search unitaries $U_{i}$, $i = 1, \\ldots, \\ell$, the `moment_matrices`-routine calculates the following matrix elements:\n",
    "\\begin{equation}\n",
    "    \\boldsymbol{\\text{H}}_{i j} = \\langle \\iota \\vert U_{i}^{\\dagger} P_{\\text{f}} C U_{j} \\vert \\iota \\rangle,\\quad\n",
    "    \\boldsymbol{\\text{E}}_{i j} = \\langle \\iota \\vert U_{i}^{\\dagger} P_{\\text{f}} U_{j} \\vert \\iota \\rangle,\\quad\n",
    "    \\boldsymbol{\\text{F}}_{i j} = \\langle \\iota \\vert U_{i}^{\\dagger} P_{\\text{if}} U_{j} \\vert \\iota \\rangle.\n",
    "\\end{equation}"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b9eaa40fd8a8548"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class Placeholder(Instruction):\n",
    "    \"\"\"\n",
    "    A child class of Qiskit's Instruction class initializing an empty instruction on a quantum circuit\n",
    "\n",
    "    ...\n",
    "\n",
    "    Attributes:\n",
    "    -----------\n",
    "    name: str\n",
    "        Name of the instruction is 'placeholder'\n",
    "\n",
    "    Methods:\n",
    "    --------\n",
    "    inverse(annotated: bool = False)\n",
    "        Initializes a new instance of an instruction placeholder.\n",
    "    \"\"\"\n",
    "    def __init__(self, num_qubits: int, label: str):\n",
    "        self.name = 'placeholder'\n",
    "        super().__init__(self.name, num_qubits, 0, [], label=label)\n",
    "\n",
    "    def inverse(self, annotated: bool = False):\n",
    "        \"\"\"\n",
    "        Initializes a new instance of an instruction placeholder.\n",
    "\n",
    "        annotated: bool\n",
    "        \"\"\"\n",
    "        return Placeholder(self.name, self.num_qubits)\n",
    "    \n",
    "def moment_matrices(simulator: AerSimulator,\n",
    "                    instance: LOP,\n",
    "                    search_unitaries: list[QuantumCircuit],\n",
    "                    shots: int) -> tuple[np.ndarray, np.ndarray, np.ndarray]:\n",
    "    \"\"\"\n",
    "    Returns the moment matrices for a given LOP instance.\n",
    "\n",
    "    simulator: AerSimulator\n",
    "        Simulator used to sample bitstring from the quantum computer\n",
    "    instance: LOP\n",
    "        Instance for which the moment matrices are computed for\n",
    "    search_unitaries:\n",
    "        Unitaries to explore the variational cone\n",
    "    shots:\n",
    "        Number of shots to estimate the moment matrices' entries\n",
    "    \"\"\"\n",
    "\n",
    "    # Number of columns and rows of the moment matrices is the number of search unitaries\n",
    "    dim: int = len(search_unitaries)\n",
    "\n",
    "    # The state altered by the search unitaries is the initial state defined in the LOP class\n",
    "    state_prep: tuple[QuantumCircuit, int] = instance.qtg()\n",
    "\n",
    "    # The number of qubits for the main register is the number of qubits needed for the state preparation\n",
    "    num_tot_qubits: int = state_prep[0].num_qubits\n",
    "\n",
    "    # Initialize a dictionary for storing the results of expectation values for candidate states\n",
    "    diagonal_results: dict[tuple[int, int], float] = {(h, i): 0.0 for h in range(3) for i in range(dim)}\n",
    "\n",
    "    # Initialize a dictionary for storing the results of Hadamard tests for superposition states\n",
    "    sp_results: dict[tuple[int, int, int, int], float] = {(g, h, i, j): 0.0 for g in range(2) for h in range(3)\n",
    "                                                          for i in range(dim) for j in range(i + 1, dim)}\n",
    "\n",
    "    result: tuple[np.ndarray, np.ndarray, np.ndarray] = (np.zeros(shape=(dim, dim), dtype=np.complex64),\n",
    "                                                         np.zeros(shape=(dim, dim), dtype=np.complex64),\n",
    "                                                         np.zeros(shape=(dim, dim), dtype=np.complex64))\n",
    "\n",
    "    anc: QuantumRegister = QuantumRegister(1, 'anc')\n",
    "\n",
    "    # Initialize the quantum register for the ancilla qubits needed to prepare the initial state\n",
    "    inactive_q: QuantumRegister = QuantumRegister(state_prep[1], 'inactive_q')\n",
    "\n",
    "    # Initialize the quantum register carrying the state altered by the search unitaries\n",
    "    q: QuantumRegister = QuantumRegister(num_tot_qubits - state_prep[1], 'q')\n",
    "\n",
    "    # Initialize a classical register carrying the measurement result of the ancilla in the Hadamard test\n",
    "    anc_c: ClassicalRegister = ClassicalRegister(1, 'anc_c')\n",
    "\n",
    "    # Initialize a classical register carrying the measurement result of the state after search unitaries were applied\n",
    "    c: ClassicalRegister = ClassicalRegister(num_tot_qubits - state_prep[1], 'c')\n",
    "\n",
    "    for i in range(dim):\n",
    "        # Initialize the quantum circuit to sample bitstrings from the application of each search unitary to the main\n",
    "        # register\n",
    "        qc_diag: QuantumCircuit = QuantumCircuit(inactive_q, q, c)\n",
    "\n",
    "        # Prepare the initial state on the main register with the aid of the preparation ancilla qubits\n",
    "        qc_diag.compose(other=state_prep[0], qubits=inactive_q[:] + q[:], inplace=True)\n",
    "\n",
    "        # Apply the current search unitary, measure the qubits shots times and assign the resulting bitstrings to the\n",
    "        # number of their appearances in a dictionary\n",
    "        qc_diag.compose(other=search_unitaries[i], qubits=q, inplace=True)\n",
    "        qc_diag.measure(qubit=q, cbit=c)\n",
    "        counts_diag: dict[str, float] = simulator.run(transpile(circuits=qc_diag, backend=simulator),\n",
    "                                                      shots=shots).result().get_counts()\n",
    "\n",
    "        # For each bitstring in the sample, if it is a feasible assignment add its relative objective value to the first\n",
    "        # and its frequency of appearance to the second of the current search unitary's diagonal entries.\n",
    "        for bs, f in counts_diag.items():\n",
    "            if instance.is_feasible(bs):\n",
    "                diagonal_results[0, i] += instance.get_objective_value(bs) * f / shots\n",
    "                diagonal_results[1, i] += f / shots\n",
    "            # If the bitstring is an infeasible assignment add its frequency of appearance to the third of the current\n",
    "            # search unitary's diagonal entries\n",
    "            else:\n",
    "                diagonal_results[2, i] += f / shots\n",
    "\n",
    "        for j in range(i + 1, dim):\n",
    "            qc_sp: QuantumCircuit = QuantumCircuit(anc, inactive_q, q, anc_c, c)\n",
    "\n",
    "            # Perform a Hadamard gate on the ancilla qubit\n",
    "            qc_sp.h(qubit=anc)\n",
    "\n",
    "            # Insert the placeholder for the phase get when computing the imaginary part\n",
    "            first_s_location: int = len(qc_sp.data)\n",
    "            qc_sp.append(Placeholder(1, label='id/s'), anc)\n",
    "\n",
    "            # Prepare the initial state on the main register with the aid of the preparation ancilla qubits\n",
    "            qc_sp.compose(other=state_prep[0], qubits=inactive_q[:] + q[:], inplace=True)\n",
    "\n",
    "            # Perform the inner loop's search unitary when the ancilla is in the zero state\n",
    "            qc_sp.compose(other=search_unitaries[j].control(num_ctrl_qubits=1, ctrl_state=0), qubits=anc[:] + q[:],\n",
    "                          inplace=True)\n",
    "\n",
    "            # Perform the outer loop's search unitary when the ancilla is in the one state\n",
    "            qc_sp.compose(other=search_unitaries[i].control(num_ctrl_qubits=1, ctrl_state=1), qubits=anc[:] + q[:],\n",
    "                          inplace=True)\n",
    "\n",
    "            # Perform another Hadamard gate on the ancilla\n",
    "            qc_sp.h(qubit=anc)\n",
    "\n",
    "            # Measure the ancilla qubit and store the result to the ancilla bit\n",
    "            qc_sp.measure(qubit=anc, cbit=anc_c)\n",
    "\n",
    "            # Measure the main register and store the result to the ancilla qubits\n",
    "            qc_sp.measure(qubit=q, cbit=c)\n",
    "\n",
    "            # Initialize a list of dictionary to later assign bitstrings to their count for the real and imaginary parts\n",
    "            # of the moment matrices' entries\n",
    "            counts_sp: list[dict[str, float]] = []\n",
    "\n",
    "            # For the real part, insert an identity to the placeholder and run the circuit, storing the counts\n",
    "            qc_sp.data[first_s_location] = CircuitInstruction(operation=IGate(), qubits=[qc_sp.qubits[0]], clbits=[])\n",
    "            counts_sp.append(simulator.run(transpile(circuits=qc_sp, backend=simulator),\n",
    "                                           shots=shots).result().get_counts())\n",
    "\n",
    "            # For the real part, insert a phase gate to the placeholder and run the circuit, storing the counts\n",
    "            qc_sp.data[first_s_location] = CircuitInstruction(operation=SGate(), qubits=[qc_sp.qubits[0]], clbits=[])\n",
    "            counts_sp.append(simulator.run(transpile(circuits=qc_sp, backend=simulator),\n",
    "                                           shots=shots).result().get_counts())\n",
    "\n",
    "            # For the real and imaginary part of all entries,\n",
    "            for g in range(2):\n",
    "                for bs, f in counts_sp[g].items():\n",
    "                    if bs[-1] == '0':\n",
    "                        if instance.is_feasible(bs[:-1]):\n",
    "                            sp_results[g, 0, i, j] += instance.get_objective_value(bs[:-1]) * f\n",
    "                            sp_results[g, 1, i, j] += f\n",
    "                        else:\n",
    "                            sp_results[g, 2, i, j] += f\n",
    "\n",
    "    for h in range(3):\n",
    "        for i in range(dim):\n",
    "            result[h][i][i] = diagonal_results[h, i]\n",
    "            for j in range(i + 1, dim):\n",
    "                result[h][i][j] = (4 * sp_results[0, h, i, j] / shots - 4j * sp_results[1, h, i, j] / shots\n",
    "                                   + (1j - 1) * (diagonal_results[h, i] + diagonal_results[h, j])) / 2\n",
    "                result[h][j][i] = np.conjugate(result[h][i][j])\n",
    "\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:10:09.698549Z",
     "start_time": "2024-04-29T21:10:09.688446Z"
    }
   },
   "id": "a80168042d621958",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "The moment matrices are finally passed to an SDP solver whose clearly defined interface with the rest of the algorithm only consists of the objective matrix $\\boldsymbol{\\text{H}}$ and both constraint matrices $\\boldsymbol{\\text{E}}$, $\\boldsymbol{\\text{F}}$. This allows to replace it with further customized SDP solvers. An exciting perspective would be to use QCP, as it is itself an SDP solver, to solve the auxiliary SDPs, produced by running QCP on larger instances.\n",
    " In any case, the solver is asked to the find the optimum to the following SDP:\n",
    "\\begin{equation}\n",
    "\\min_{\\boldsymbol{\\text{X}}} \\text{tr}(\\boldsymbol{\\text{H}}\\, \\boldsymbol{\\text{X}}) \\\\\n",
    "\\text{s.t.}\\ \\text{tr}(\\boldsymbol{\\text{E}}\\, \\boldsymbol{\\text{X}}) = 1 \\\\\n",
    "\\text{tr}(\\boldsymbol{\\text{F}}\\, \\boldsymbol{\\text{X}}) = 0 \\\\\n",
    "\\boldsymbol{\\text{X}} \\succeq 0.\n",
    "\\end{equation}\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9f02d582035ac31d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "class SDPException(Exception):\n",
    "    \"\"\"\n",
    "    Raised when the auxiliary SDP could not be solved\n",
    "    \"\"\"\n",
    "    pass\n",
    "\n",
    "def solve_auxiliary_gep(obj_mat: np.ndarray, feasible_mat: np.ndarray, infeasible_mat: np.ndarray) -> tuple[np.ndarray, float]:\n",
    "    delta: float = 0.00001\n",
    "    eigenvalues_constr_mat, transformation = eigh(feasible_mat, check_finite=False)\n",
    "    reduced_obj_mat: np.ndarray = np.conjugate(transformation.T) @ obj_mat @ transformation\n",
    "    reduced_infeasible_mat: np.ndarray = np.conjugate(transformation.T) @ infeasible_mat @ transformation\n",
    "    kernel_dim: int = sum(e < 10 ** (-4) for e in eigenvalues_constr_mat)\n",
    "    if kernel_dim != 0:\n",
    "        eigenvalues_constr_mat = eigenvalues_constr_mat[kernel_dim:]\n",
    "        mask = np.append(np.zeros(kernel_dim, bool), np.ones(reduced_obj_mat.shape[0] - kernel_dim, bool))\n",
    "        reduced_obj_mat = reduced_obj_mat[mask, :][:, mask]\n",
    "        reduced_infeasible_mat = reduced_infeasible_mat[mask, :][:, mask]\n",
    "        \n",
    "    reduced_feasible_mat: np.ndarray = np.diag(eigenvalues_constr_mat.astype(np.complex64))\n",
    "    prob = picos.Problem()\n",
    "    x = picos.HermitianVariable(\"X\", len(reduced_obj_mat))\n",
    "    h = picos.Constant(\"H\", reduced_obj_mat.tolist())\n",
    "    e = picos.Constant(\"E\", reduced_feasible_mat.tolist())\n",
    "    f = picos.Constant(\"F\", reduced_infeasible_mat.tolist())\n",
    "    prob.set_objective(\"min\", picos.trace(h * x).real)\n",
    "    prob.add_constraint(x >> 0)\n",
    "    prob.add_constraint(picos.trace(e * x).real >= 1 - delta)\n",
    "    prob.add_constraint(picos.trace(e * x).real <= 1 + delta)\n",
    "    prob.add_constraint(picos.trace(f * x).real >= 0 - delta)\n",
    "    prob.add_constraint(picos.trace(f * x).real <= 0 + delta)\n",
    "    # prob.add_constraint(picos.trace(e * x).real == 1)\n",
    "    # prob.add_constraint(picos.trace(f * x).real == 0)\n",
    "    try:\n",
    "        prob.solve()\n",
    "        solution: np.ndarray = np.array(x.value)\n",
    "        enlarged_solution = np.zeros(shape=obj_mat.shape, dtype=np.complex64)\n",
    "        enlarged_solution[obj_mat.shape[0] - solution.shape[0]:, obj_mat.shape[1] - solution.shape[1]:] = solution\n",
    "        result = transformation.T @ enlarged_solution @ np.conjugate(transformation.T), prob.value\n",
    "    except (ValueError, IndexError, picos.modeling.problem.SolutionFailure):\n",
    "        print(f\"SDP {prob.status}; {prob.value}\")\n",
    "        raise SDPException\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:10:11.088889Z",
     "start_time": "2024-04-29T21:10:11.083130Z"
    }
   },
   "id": "735f9e7eb90327db",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "instance1 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance1.assign_parts({1: 1, 2: 3, 3: 2, 4: 5, 5: 5, 6: 1, 7: 2, 8: 1, 9: 1})\n",
    "\n",
    "instance2 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance2.assign_parts({1: 1, 2: 3, 3: 2, 4: 5, 5: 5, 6: 1, 7: 2, 8: 1})\n",
    "\n",
    "instance3 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance3.assign_parts({1: 1, 2: 3, 3: 2, 4: 5, 5: 5, 6: 1, 7: 2})\n",
    "\n",
    "instance4 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance4.assign_parts({1: 1, 2: 3, 3: 2, 4: 5, 5: 5, 6: 1})\n",
    "\n",
    "instance5 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance5.assign_parts({1: 1, 2: 3, 3: 2, 4: 5, 5: 5})\n",
    "\n",
    "instance6 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance6.assign_parts({1: 1, 2: 3, 3: 2, 4: 5})\n",
    "\n",
    "instance7 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance7.assign_parts({1: 1, 2: 3, 3: 2})\n",
    "\n",
    "instance8 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance8.assign_parts({1: 1, 2: 3})\n",
    "\n",
    "instance9 = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "instance9.assign_parts({1: 1})\n",
    "\n",
    "instance_final = LOP('cost_10_07.csv', 'pbs_10.csv')\n",
    "\n",
    "def report(instance: LOP):\n",
    "    print(f'Number of products: {instance.num_parts}')\n",
    "    print(f'Number of sites: {instance.num_sites}')\n",
    "    print(f'Phi constraints: {instance.phi}')\n",
    "    print(f'Reduced phi constraints: {instance.reduced_phi}')\n",
    "    print(f'Psi constraints: {instance.psi}')\n",
    "    print(f'Reduced psi constraints: {instance.reduced_psi}')\n",
    "    print(f'Products: {instance.parts}')\n",
    "    print(f'Number of layers: {instance.layers}')\n",
    "    print(f'Free parts: {instance.free_parts}')\n",
    "    print(f'Available sites: {instance.available_sites}')\n",
    "    print(f'Maximum product: {instance.max_part}')\n",
    "    print(f'Number of variables: {instance.num_var}')\n",
    "    print(f'Assigned cost: {instance.assigned_costs}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:10:11.770973Z",
     "start_time": "2024-04-29T21:10:11.762Z"
    }
   },
   "id": "12a1ea4f364493eb",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def controlled_unitary(search_unitaries: list[QuantumCircuit]) -> QuantumCircuit:\n",
    "    dim: int = len(search_unitaries)\n",
    "    num_main_qubits: int = search_unitaries[0].num_qubits\n",
    "    num_anc_qubits: int = (dim - 1).bit_length()\n",
    "    result: QuantumCircuit = QuantumCircuit(QuantumRegister(num_anc_qubits + num_main_qubits))\n",
    "    for i in range(dim):\n",
    "        result.compose(search_unitaries[i].control(num_ctrl_qubits=num_anc_qubits, ctrl_state=i), inplace=True)\n",
    "    return result\n",
    "\n",
    "def lcu(init_state: tuple[QuantumCircuit, int], aux_state: np.ndarray,\n",
    "        search_unitaries: list[QuantumCircuit]) -> QuantumCircuit:\n",
    "    num_ctrl_qubits: int = (len(search_unitaries) - 1).bit_length()\n",
    "    aux_state_reg: QuantumRegister = QuantumRegister(num_ctrl_qubits, 'aux_state')\n",
    "    state_anc_reg: QuantumRegister = QuantumRegister(init_state[1], 'state_anc')\n",
    "    state_main_reg: QuantumRegister = QuantumRegister(init_state[0].num_qubits - init_state[1], 'state_main')\n",
    "    qc: QuantumCircuit = QuantumCircuit(aux_state_reg, state_anc_reg, state_main_reg)\n",
    "    qc.compose(init_state[0], list(state_anc_reg) + list(state_main_reg), inplace=True)\n",
    "    qc.compose(\n",
    "        StatePreparation(params=list(aux_state) + [0.0 for _ in range((1 << num_ctrl_qubits) - len(search_unitaries))],\n",
    "                         normalize=True), qubits=aux_state_reg, inplace=True)\n",
    "    for i in range(len(search_unitaries)):\n",
    "        qc.compose(search_unitaries[i].control(num_ctrl_qubits=num_ctrl_qubits, ctrl_state=i),\n",
    "                   qubits=list(aux_state_reg) + list(state_main_reg), inplace=True)\n",
    "    superposition: list[float] = ([1 / sqrt(len(search_unitaries)) for _ in range(len(search_unitaries))]\n",
    "                                  + [0.0 for _ in\n",
    "                                     range((1 << (len(search_unitaries) - 1).bit_length()) - len(search_unitaries))])\n",
    "    qc.compose(StatePreparation(params=list(superposition), normalize=True).inverse(),\n",
    "               qubits=aux_state_reg, inplace=True)\n",
    "\n",
    "    return qc"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:10:19.270042Z",
     "start_time": "2024-04-29T21:10:19.265652Z"
    }
   },
   "id": "3bd6d40cec7b24c8",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "def qcp(simulator: AerSimulator, instance: LOP, search_unitaries: list[QuantumCircuit], matrix_shots: int = 1024, sample_shots: int = 256, final_shots: int = 256) -> tuple[dict[int, int], float]:\n",
    "    obj_mat, feasible_mat, infeasible_mat = moment_matrices(simulator=simulator, instance=instance, search_unitaries=search_unitaries, shots=matrix_shots)\n",
    "    aux_state, _ = solve_auxiliary_gep(obj_mat=obj_mat, feasible_mat=feasible_mat, infeasible_mat=infeasible_mat)\n",
    "    aux_size: int = len(search_unitaries)\n",
    "    num_aux_qubits: int = (aux_size - 1).bit_length()\n",
    "    probabilities, pure_states = eigh(aux_state)\n",
    "    neglected_dim: int = sum(p < 10 ** (-4) for p in probabilities)\n",
    "    probabilities = probabilities[neglected_dim:]\n",
    "    pure_states = pure_states.T[neglected_dim:]\n",
    "    samples = Counter(choices(population=range(aux_size - neglected_dim), weights=probabilities, k=sample_shots))\n",
    "    init_state: tuple[QuantumCircuit, int] = instance.qtg()\n",
    "    qcp_counts_trimmed: dict[str, int] = {}\n",
    "    qcp_feasible_shots: int = 0\n",
    "    for (state_index, shots) in samples.items():\n",
    "        state: np.ndarray = pure_states[state_index]\n",
    "        qcp_circuit: QuantumCircuit = lcu(init_state=init_state,\n",
    "                                          aux_state=state,\n",
    "                                          search_unitaries=search_unitaries)\n",
    "        qcp_circuit.measure_all(inplace=True, add_bits=True)\n",
    "        qcp_counts = simulator.run(transpile(circuits=qcp_circuit, backend=simulator), shots=shots * final_shots).result().get_counts()\n",
    "        for bs, c in qcp_counts.items():\n",
    "            if bs[-num_aux_qubits:] == '0' * num_aux_qubits:\n",
    "                bs_trimmed = bs[:qcp_circuit.num_qubits - num_aux_qubits - init_state[1]]\n",
    "                qcp_counts_trimmed[bs_trimmed] = qcp_counts_trimmed.get(bs_trimmed, 0) + c\n",
    "                qcp_feasible_shots += c\n",
    "    minimizer: dict[int, int] = {}\n",
    "    minimum: float = np.inf\n",
    "    for bs in qcp_counts_trimmed.keys():\n",
    "        if instance.is_feasible(bs):\n",
    "            if instance.get_objective_value(bs) < minimum:\n",
    "                minimizer = instance.assignment_from_bitstring(bs) | instance.get_assignment()\n",
    "                minimum = instance.get_objective_value(bs)\n",
    "    return minimizer, minimum"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:10:23.826958Z",
     "start_time": "2024-04-29T21:10:23.820060Z"
    }
   },
   "id": "6ef0e7529f136d69",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "CTG_SHOTS: int = 512\n",
    "MAX_QUBITS: int = 12\n",
    "SIMULATOR: AerSimulator = AerSimulator()\n",
    "MATRIX_SHOTS: int = 1024\n",
    "SAMPLE_SHOTS: int = 256\n",
    "FINAL_SHOTS: int = 256\n",
    "\n",
    "def bound(instance: LOP) -> tuple[float, tuple[dict[int, int], float]]:\n",
    "    # derive lower bound via relaxation\n",
    "    model: gp.Model = instance.create_model()\n",
    "    model.setParam('IterationLimit', 200)\n",
    "    model.reset()\n",
    "    model.optimize()\n",
    "    lower_bound: float = model.ObjBound\n",
    "    \n",
    "    #derive upper bound via finding a good feasible state\n",
    "    if instance.num_var <= MAX_QUBITS:\n",
    "        upper_sol, upper_bound = qcp(SIMULATOR, instance, instance.search_unitaries(), MATRIX_SHOTS, SAMPLE_SHOTS, FINAL_SHOTS)\n",
    "    else:\n",
    "        model.reset()\n",
    "        model.setParam('IterationLimit', 50)\n",
    "        model.optimize()\n",
    "        assigned: dict[int, int] = instance.assignment_from_bitstring(''.join(format(x, 'b')for x in reversed([int(var.X) for var in model.getVars()])))\n",
    "        upper_sol: dict[int, int] = instance.get_assignment() | assigned\n",
    "        upper_bound: float = model.ObjVal\n",
    "    return lower_bound, (upper_sol, upper_bound)\n",
    "        \n",
    "    \n",
    "\n",
    "def branch_and_bound(instance: LOP) -> tuple[dict[int, int], float]:\n",
    "    solution, global_upper_bound = instance.ctg(shots=CTG_SHOTS)\n",
    "    print(f'Initial solution (provided by CTG): {solution}')\n",
    "    print(f'Initial upper bound (provided by CTG): {global_upper_bound}')\n",
    "    instance_queue: Queue = Queue()\n",
    "    instance_queue.put(instance)\n",
    "    current_layer: int = 1\n",
    "    current_num_parts: int = len(instance.free_parts) + 1\n",
    "    while not instance_queue.empty():\n",
    "        current_instance: LOP = instance_queue.get()\n",
    "        if len(current_instance.free_parts) < current_num_parts:\n",
    "            print(f'\\nEntering layer {current_layer}\\n' + ('-' * 20))\n",
    "            current_layer += 1\n",
    "            current_num_parts = len(current_instance.free_parts)\n",
    "        if current_instance.num_var == 0:\n",
    "            objective_value: float = current_instance.get_objective_value_inplace()\n",
    "            if objective_value < global_upper_bound:\n",
    "                solution = current_instance.get_assignment()\n",
    "                global_upper_bound = objective_value\n",
    "                print(f'Updated solution: {solution} ({global_upper_bound}) via direct calculation')\n",
    "        else:\n",
    "            current_bounds: tuple[float, tuple[dict[int, int], float]] = bound(current_instance)\n",
    "            if current_bounds[0] >= global_upper_bound:\n",
    "                continue\n",
    "        \n",
    "            if current_bounds[1][1] < global_upper_bound:\n",
    "                solution, global_upper_bound = current_bounds[1]\n",
    "                print(f'Updated solution: {solution} ({global_upper_bound}) via upper bound heuristic')\n",
    "            \n",
    "            current_part: int = max(current_instance.free_parts)\n",
    "            for site in current_instance.available_sites[current_part]:\n",
    "                subinstance: LOP = deepcopy(current_instance)\n",
    "                subinstance.assign_parts_inplace({current_part: site})\n",
    "                instance_queue.put(subinstance)\n",
    "                \n",
    "    return solution, global_upper_bound"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-29T21:20:35.406138Z",
     "start_time": "2024-04-29T21:20:35.386353Z"
    }
   },
   "id": "99c616c044542a90",
   "execution_count": 20
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
